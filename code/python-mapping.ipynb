{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "#show me all the columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behind the scenes with geo files\n",
    "\n",
    "Helpful Minneapolis codes:\n",
    "- Minnesota is state fips 27\n",
    "- Minneapolis is in Hennepin County, which is county fips 27053.\n",
    "\n",
    "Where to download/find these GIS files for your state!\n",
    "- **Schools:** [The NCES EDGE open data portal](https://data-nces.opendata.arcgis.com/) contains all sorts of helpful data, including school locations.\n",
    "- **Neighborhoods:** check your city GIS site\n",
    "- **Toxic Release Inventory:** Multiple years and states [available here](https://www.epa.gov/toxics-release-inventory-tri-program/tri-basic-data-files-calendar-years-1987-present)\n",
    "- **Census Tigerline URLs:** [pick your vintage here](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html), then click FTP Archive and navigate to the shapefile you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_base = '../GIS'\n",
    "\n",
    "#importing shapefiles and geojson\n",
    "schools = gpd.read_file(f'{gis_base}/nces-mn-schools.geojson')\n",
    "\n",
    "#importing from zip\n",
    "hoods = gpd.read_file(f'{gis_base}/Minneapolis_Neighborhoods_4501150611105070206.zip')\n",
    "\n",
    "#importing from url\n",
    "tracts = gpd.read_file('https://www2.census.gov/geo/tiger/TIGER2024/TRACT/tl_2024_27_tract.zip')\n",
    "\n",
    "#importing points from csv\n",
    "tri = pd.read_csv(f'{gis_base}/epa-tri-2023-mn.csv')\n",
    "tri = gpd.GeoDataFrame(tri, geometry=gpd.points_from_xy(tri['13. LONGITUDE'], tri['12. LATITUDE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring geodata is just like exploring any other dataframe\n",
    "print('School count:',len(schools))\n",
    "print(schools.dtypes)\n",
    "display(schools.head())\n",
    "\n",
    "\n",
    "#look the geometry!\n",
    "print(schools.geometry)\n",
    "\n",
    "#we can get the projection real quick too\n",
    "print('Coordinate reference system:',schools.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now you try looking at the other geodataframes crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cam is gonna talk about projects here for a minute. They're important friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick viz\n",
    "schools.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slaying with APIs\n",
    "A lot of ArcGIS maps have helpful API portals that will walk you thru querying and downloading the geojson.\n",
    "\n",
    "Here's a video that shows you how to find that query page when you're looking at an ArcGIS map online:\n",
    "\n",
    "Some of the data you try and pull down will clearly be accessible via API. Here's a video that shows you how to find the API page: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's grab some data from the Minneapolis Open Data portal\n",
    "potholes = gpd.read_file(\"https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Public_311_2024/FeatureServer/0/query?where=TYPENAME%20%3D%20'Pothole'&outFields=*&outSR=4326&f=json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(potholes))\n",
    "display(potholes.head())\n",
    "potholes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes an API requires an access key\n",
    "#here's an example oh how to get Census ACS 5-yr data via the API\n",
    "#and more info on the various APIs https://www.census.gov/data/developers/data-sets/acs-5year.html\n",
    "#NOTE: different tables (detailed, subject, etc) have different geography levels available\n",
    "def get_census_data(year,var_str,rename_cols):\n",
    "    data_url = f'https://api.census.gov/data/{str(year)}/acs/acs5/subject?get={var_str}&for=tract:*&in=state:27%20county:053&key={MYKEY}'\n",
    "    census_df = pd.read_json(data_url)\n",
    "    new_header = census_df.iloc[0] #grab the first row for the header\n",
    "    census_df = census_df[1:] #take the data less the header row\n",
    "    census_df.columns = new_header #set the header row as the df header\n",
    "    census_df.rename(columns=rename_cols, inplace=True) #heres where we actually rename\n",
    "\n",
    "    #I recommend saving your API data to a file so you're not constantly hitting the API\n",
    "    #census_df.to_csv(f'../data/analyzed/{str(year)}ACS5yr-hennipen-mn-tract-data.csv',index=False)\n",
    "    \n",
    "    return census_df\n",
    "\n",
    "MYKEY = os.environ['census_api_key']\n",
    "\n",
    "rename_cols = {\n",
    "    'S0101_C01_001E':'pop',\n",
    "    'S1901_C01_001E':'households',\n",
    "    'S1901_C01_012E':'median_income',\n",
    "    }\n",
    "\n",
    "var_list = ['GEO_ID','NAME']+list(rename_cols.keys())\n",
    "var_str = ','.join(var_list)\n",
    "   \n",
    "data_2023 = get_census_data(2023,var_str,rename_cols)\n",
    "\n",
    "#convert our data columns to numeric\n",
    "data_2023['pop'] = pd.to_numeric(data_2023['pop'],errors='coerce')\n",
    "data_2023['households'] = pd.to_numeric(data_2023['households'],errors='coerce')\n",
    "data_2023['median_income'] = pd.to_numeric(data_2023['median_income'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "GEO_ID           object\n",
      "NAME             object\n",
      "pop               int64\n",
      "households        int64\n",
      "median_income     int64\n",
      "state            object\n",
      "county           object\n",
      "tract            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_2023.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial joins and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter one dataset by another\n",
    "potholes_in_hoods = gpd.sjoin(potholes, hoods, predicate='within')\n",
    "\n",
    "#remember, gdfs need to be in the same projection for spatial joins\n",
    "potholes_4326 = potholes.to_crs(epsg=4326)\n",
    "hoods_4326 = hoods.to_crs(epsg=4326)\n",
    "\n",
    "potholes_in_hoods = gpd.sjoin(potholes_4326, hoods_4326, predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(potholes))\n",
    "print(len(potholes_in_hoods))\n",
    "potholes_in_hoods.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count points in polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosswalks\n",
    "Generally, demographic data like population and median income isn't calculated for custom geographies like neighborhoods. But no matter! We can calculate that sort of information for ourselves using crosswalks.\n",
    "\n",
    "In this example, we are going to cross Census tracts with Minneapolis neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Add census data to the tracts\n",
    "#####################\n",
    "\n",
    "#make sure we can join on the GEOID cols\n",
    "data_2023['GEOID'] = data_2023['GEO_ID'].str.replace('1400000US','')\n",
    "\n",
    "#join\n",
    "tracts_data = tracts.merge(data_2023, on='GEOID', how='left')\n",
    "print(len(tracts_data.loc[~tracts_data['pop'].isnull()]))\n",
    "\n",
    "#make sure both gdfs are in the same projection and that projection uses meters or feet\n",
    "tracts_data = tracts_data.to_crs(epsg=6505)\n",
    "hoods = hoods.to_crs(epsg=6505)\n",
    "\n",
    "#and we'll need to calculate the area of the tracts before and after we do the intersection so we can\n",
    "#calculate the actual estimated count of people of different races in each tract segmemt.\n",
    "tracts_data['pre_area'] = tracts_data['geometry'].area\n",
    "\n",
    "#now let's do that intersection!\n",
    "tracts_hoods = gpd.overlay(tracts_data, hoods, how='intersection')\n",
    "\n",
    "#and calculate the area post intersection.  \n",
    "tracts_hoods['post_area'] = tracts_hoods['geometry'].area\n",
    "\n",
    "#from the pre and post area calculations we create a percentage\n",
    "tracts_hoods['pct_area'] = tracts_hoods['post_area']/tracts_hoods['pre_area']\n",
    "\n",
    "#and then we multiply our tract data counts by that percentage\n",
    "#to get estimates per segments of the tract that falls within each hood\n",
    "tracts_hoods['post_pop'] = tracts_hoods['pop'] * tracts_hoods['pct_area']\n",
    "tracts_hoods['post_households'] = tracts_hoods['households'] * tracts_hoods['pct_area']\n",
    "tracts_hoods['post_income'] = tracts_hoods['median_income'] * tracts_hoods['pct_area']\n",
    "\n",
    "#groupby the neighborhood name so we can join back to our neighborhood shapes\n",
    "hoods_data = tracts_hoods.groupby('BDNAME').agg({'post_pop':'sum',\n",
    "                                                 'post_households':'sum',\n",
    "                                                 'post_income':'mean'\n",
    "                                                 }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDNAME</th>\n",
       "      <th>post_pop</th>\n",
       "      <th>post_households</th>\n",
       "      <th>post_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>4927.272657</td>\n",
       "      <td>1930.251413</td>\n",
       "      <td>32059.390183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audubon Park</td>\n",
       "      <td>4795.355401</td>\n",
       "      <td>2100.987299</td>\n",
       "      <td>24809.378513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bancroft</td>\n",
       "      <td>3628.632091</td>\n",
       "      <td>1503.555573</td>\n",
       "      <td>20924.895937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beltrami</td>\n",
       "      <td>495.480057</td>\n",
       "      <td>198.526625</td>\n",
       "      <td>3630.264787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bottineau</td>\n",
       "      <td>1697.177095</td>\n",
       "      <td>768.063281</td>\n",
       "      <td>16686.740509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BDNAME     post_pop  post_households   post_income\n",
       "0      Armatage  4927.272657      1930.251413  32059.390183\n",
       "1  Audubon Park  4795.355401      2100.987299  24809.378513\n",
       "2      Bancroft  3628.632091      1503.555573  20924.895937\n",
       "3      Beltrami   495.480057       198.526625   3630.264787\n",
       "4     Bottineau  1697.177095       768.063281  16686.740509"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoods_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting for viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
